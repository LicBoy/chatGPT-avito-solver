{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:22:21.933336Z","iopub.status.busy":"2023-05-18T21:22:21.932851Z","iopub.status.idle":"2023-05-18T21:22:29.575446Z","shell.execute_reply":"2023-05-18T21:22:29.574208Z","shell.execute_reply.started":"2023-05-18T21:22:21.933243Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","from collections import Counter\n","\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification, get_cosine_schedule_with_warmup, AdamW"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:22:29.578737Z","iopub.status.busy":"2023-05-18T21:22:29.577800Z","iopub.status.idle":"2023-05-18T21:22:29.795635Z","shell.execute_reply":"2023-05-18T21:22:29.794735Z","shell.execute_reply.started":"2023-05-18T21:22:29.578691Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['Да', 'Нет', 'Чат неинформативный']"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv('/kaggle/input/sold-chat-data/train.csv')\n","test = pd.read_csv('/kaggle/input/sold-chat-data/test.csv')\n","# sample_submission = pd.read_csv('/kaggle/input/russian-social-media-text-classification/sample_submission.csv')\n","CLASSES = list(train['predict'].unique())\n","CLASSES"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:22:29.798697Z","iopub.status.busy":"2023-05-18T21:22:29.798028Z","iopub.status.idle":"2023-05-18T21:22:29.811702Z","shell.execute_reply":"2023-05-18T21:22:29.810772Z","shell.execute_reply.started":"2023-05-18T21:22:29.798658Z"},"trusted":true},"outputs":[],"source":["labels = dict(zip(CLASSES, range(len(CLASSES))))\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, tokenizer, phase='test'):\n","        self.phase = phase\n","        \n","        if self.phase == 'train':\n","            self.labels = [labels[label] for label in df['category']]\n","        elif self.phase == 'test':\n","            self.oid = [oid for oid in df['oid']]\n","            \n","        self.texts = [tokenizer(text, \n","                               padding='max_length', max_length = 2048, truncation=True,\n","                                return_tensors=\"pt\") for text in df['text']]\n","\n","    def classes(self):\n","        return self.labels\n","\n","    def __len__(self):\n","        if self.phase == 'train':\n","            return len(self.labels)\n","        elif self.phase == 'test':\n","            return len(self.oid)\n","\n","    def get_batch_labels(self, idx):\n","        return np.array(self.labels[idx])\n","    \n","    def get_batch_oid(self, idx):\n","        return np.array(self.oid[idx])\n","\n","    def get_batch_texts(self, idx):\n","        return self.texts[idx]\n","\n","    def __getitem__(self, idx):\n","        if self.phase == 'train':\n","            batch_texts = self.get_batch_texts(idx)\n","            batch_y = self.get_batch_labels(idx)\n","            return batch_texts, batch_y\n","        elif self.phase == 'test':\n","            batch_texts = self.get_batch_texts(idx)\n","            batch_oid = self.get_batch_oid(idx)\n","            return batch_texts, batch_oid\n","   "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:22:29.817342Z","iopub.status.busy":"2023-05-18T21:22:29.816823Z","iopub.status.idle":"2023-05-18T21:22:29.843106Z","shell.execute_reply":"2023-05-18T21:22:29.842148Z","shell.execute_reply.started":"2023-05-18T21:22:29.817309Z"},"trusted":true},"outputs":[],"source":["class BertClassifier:\n","    def __init__(self, model_path, tokenizer_path, data, n_classes=3, epochs=5):\n","        self.model = BertForSequenceClassification.from_pretrained(model_path)\n","        self.tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n","        self.data = data\n","        self.device = torch.device('cuda')\n","        self.max_len = 512\n","        self.epochs = epochs\n","        self.out_features = self.model.bert.encoder.layer[1].output.dense.out_features\n","        self.model.classifier = torch.nn.Linear(self.out_features, n_classes).cuda()\n","        self.model = self.model.cuda()\n","\n","    \n","    def preparation(self):\n","        self.df_train, self.df_val, self.df_test = np.split(self.data.sample(frac=1, random_state=42), \n","                                     [int(.85*len(self.data)), int(.95*len(self.data))])\n","        \n","        self.train, self.val = CustomDataset(self.df_train, self.tokenizer, phase='train'), CustomDataset(self.df_val, self.tokenizer, phase='train')\n","        self.train_dataloader = torch.utils.data.DataLoader(self.train, batch_size=4, shuffle=True)\n","        self.val_dataloader = torch.utils.data.DataLoader(self.val, batch_size=4)\n","    \n","       \n","        self.optimizer = AdamW(self.model.parameters(), lr=2e-5, correct_bias=False)\n","        self.scheduler = get_cosine_schedule_with_warmup(\n","                self.optimizer,\n","                num_warmup_steps=0,\n","                num_training_steps=len(self.train_dataloader) * self.epochs\n","            )\n","        self.loss_fn = torch.nn.CrossEntropyLoss().cuda()\n","            \n","    def fit(self):\n","        self.model = self.model.train()\n","        \n","        for epoch_num in range(self.epochs):\n","            total_acc_train = 0\n","            total_loss_train = 0\n","            for train_input, train_label in tqdm(self.train_dataloader):\n","                train_label = train_label.cuda()\n","                mask = train_input['attention_mask'].cuda()\n","                input_id = train_input['input_ids'].squeeze(1).cuda()\n","                output = self.model(input_id.cuda(), mask.cuda())\n","\n","                batch_loss = self.loss_fn(output[0], train_label.long())\n","                total_loss_train += batch_loss.item()\n","\n","                acc = (output[0].argmax(dim=1) == train_label).sum().item()\n","                total_acc_train += acc\n","\n","                self.model.zero_grad()\n","                batch_loss.backward()\n","                self.optimizer.step()\n","                self.scheduler.step()\n","            total_acc_val, total_loss_val = self.eval()\n","           \n","            print(\n","            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(self.df_train): .3f} \\\n","            | Train Accuracy: {total_acc_train / len(self.df_train): .3f} \\\n","            | Val Loss: {total_loss_val / len(self.df_val): .3f} \\\n","            | Val Accuracy: {total_acc_val / len(self.df_val): .3f}')\n","\n","            \n","            os.makedirs('checkpoint', exist_ok=True)\n","            torch.save(self.model, f'checkpoint/BertClassifier{epoch_num}.pt')\n","\n","        return total_acc_train, total_loss_train\n","    \n","    def eval(self):\n","        self.model = self.model.eval()\n","        total_acc_val = 0\n","        total_loss_val = 0\n","\n","        with torch.no_grad():\n","            for val_input, val_label in tqdm(self.val_dataloader):\n","                val_label = val_label.cuda()\n","                mask = val_input['attention_mask'].cuda()\n","                input_id = val_input['input_ids'].squeeze(1).cuda()\n","\n","                output = self.model(input_id.to('cuda'), mask.to('cuda'))\n","\n","                batch_loss = self.loss_fn(output[0], val_label.long())\n","                total_loss_val += batch_loss.item()\n","\n","                acc = (output[0].argmax(dim=1) == val_label).sum().item()\n","                total_acc_val += acc\n","            \n","        return total_acc_val, total_loss_val\n","    "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:22:29.845291Z","iopub.status.busy":"2023-05-18T21:22:29.844613Z","iopub.status.idle":"2023-05-18T21:22:44.348799Z","shell.execute_reply":"2023-05-18T21:22:44.347723Z","shell.execute_reply.started":"2023-05-18T21:22:29.845255Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50fefa9766c64d43aedd810d6313688b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/632 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cacadf52549b4fa48105801fa6613f6d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/45.5M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e585ec991e84f1e8320da4fa7448f43","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/235k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f7e6d35467b4faeba7c19320dd97fed","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a55f23d9f3941bf8b709fcf8c6617c6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/341 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_path = 'cointegrated/rubert-tiny'\n","tokenizer_path = 'cointegrated/rubert-tiny'\n","bert_tiny = BertClassifier(model_path, tokenizer_path, train, epochs=3)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:22:44.350885Z","iopub.status.busy":"2023-05-18T21:22:44.350483Z","iopub.status.idle":"2023-05-18T21:23:13.165537Z","shell.execute_reply":"2023-05-18T21:23:13.164556Z","shell.execute_reply.started":"2023-05-18T21:22:44.350843Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 28.6 s, sys: 102 ms, total: 28.7 s\n","Wall time: 28.8 s\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["%%time\n","bert_tiny.preparation()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:23:13.167738Z","iopub.status.busy":"2023-05-18T21:23:13.167050Z","iopub.status.idle":"2023-05-18T21:24:20.058671Z","shell.execute_reply":"2023-05-18T21:24:20.057629Z","shell.execute_reply.started":"2023-05-18T21:23:13.167694Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 904/904 [00:22<00:00, 39.70it/s]\n","100%|██████████| 107/107 [00:00<00:00, 139.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs: 1 | Train Loss:  0.177             | Train Accuracy:  0.680             | Val Loss:  0.157             | Val Accuracy:  0.728\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 904/904 [00:21<00:00, 42.62it/s]\n","100%|██████████| 107/107 [00:00<00:00, 134.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs: 2 | Train Loss:  0.142             | Train Accuracy:  0.760             | Val Loss:  0.144             | Val Accuracy:  0.737\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 904/904 [00:20<00:00, 44.95it/s]\n","100%|██████████| 107/107 [00:00<00:00, 138.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs: 3 | Train Loss:  0.127             | Train Accuracy:  0.796             | Val Loss:  0.143             | Val Accuracy:  0.735\n"]},{"data":{"text/plain":["(2878, 460.6930696219206)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["bert_tiny.fit()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:24:20.061245Z","iopub.status.busy":"2023-05-18T21:24:20.060469Z","iopub.status.idle":"2023-05-18T21:24:20.141575Z","shell.execute_reply":"2023-05-18T21:24:20.140693Z","shell.execute_reply.started":"2023-05-18T21:24:20.061204Z"},"trusted":true},"outputs":[],"source":["test_dataset = CustomDataset(test, bert_tiny.tokenizer, phase='test')\n","test_dataloader = DataLoader(test_dataset, batch_size=4)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:24:20.143137Z","iopub.status.busy":"2023-05-18T21:24:20.142776Z","iopub.status.idle":"2023-05-18T21:24:20.154871Z","shell.execute_reply":"2023-05-18T21:24:20.153800Z","shell.execute_reply.started":"2023-05-18T21:24:20.143098Z"},"trusted":true},"outputs":[],"source":["def inference(model, dataloader):\n","    all_oid = []\n","    all_labels = []\n","    label_prob = []\n","    \n","    model.cuda()\n","    model.eval()\n","    with torch.no_grad():\n","        for test_input, test_oid in tqdm(dataloader):\n","            test_oid = test_oid.cuda()\n","            mask = test_input['attention_mask'].cuda()\n","            input_id = test_input['input_ids'].squeeze(1).cuda()\n","            output = model(input_id, mask)\n","            all_oid.extend(test_oid)\n","            all_labels.extend(torch.argmax(output[0].softmax(1), dim=1))\n","            \n","            for prob in output[0].softmax(1):\n","                label_prob.append(prob)\n","        return ([oid.item() for oid in all_oid], [CLASSES[labels] for labels in all_labels], label_prob)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:24:20.159354Z","iopub.status.busy":"2023-05-18T21:24:20.158934Z","iopub.status.idle":"2023-05-18T21:24:20.241653Z","shell.execute_reply":"2023-05-18T21:24:20.240654Z","shell.execute_reply.started":"2023-05-18T21:24:20.159320Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [00:00<00:00, 168.74it/s]\n"]}],"source":["inference_model = torch.load(f'/kaggle/working/checkpoint/BertClassifier{bert_tiny.epochs-1}.pt')\n","inference_result = inference(inference_model, test_dataloader)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:24:20.243663Z","iopub.status.busy":"2023-05-18T21:24:20.243284Z","iopub.status.idle":"2023-05-18T21:24:20.252194Z","shell.execute_reply":"2023-05-18T21:24:20.251068Z","shell.execute_reply.started":"2023-05-18T21:24:20.243624Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["12\n","12\n","12\n"]}],"source":["oid = [i for i in inference_result[0]]\n","labels = [i for i in inference_result[1]]\n","prob = [i for i in inference_result[2]]\n","print(len(dict(zip(oid, labels))))\n","print(len(set(oid) & set(test['oid'].unique())))\n","print(len(set(oid) & set(test['oid'].unique())))"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:24:20.254411Z","iopub.status.busy":"2023-05-18T21:24:20.254010Z","iopub.status.idle":"2023-05-18T21:24:20.262692Z","shell.execute_reply":"2023-05-18T21:24:20.261103Z","shell.execute_reply.started":"2023-05-18T21:24:20.254374Z"},"trusted":true},"outputs":[],"source":["detached_prob = []\n","for i in prob:\n","    detached_prob.append(i.cpu().numpy())"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-05-18T21:24:20.264916Z","iopub.status.busy":"2023-05-18T21:24:20.264484Z","iopub.status.idle":"2023-05-18T21:24:20.293250Z","shell.execute_reply":"2023-05-18T21:24:20.292332Z","shell.execute_reply.started":"2023-05-18T21:24:20.264876Z"},"trusted":true},"outputs":[],"source":["data = {'oid':oid, 'predict':labels, 'probs':detached_prob}\n","submit = pd.DataFrame(data)\n","submit['label_int'] = submit['predict'].apply(lambda x: CLASSES.index(x))\n","\n","label_int = submit['label_int'].to_list()\n","probs = submit['probs'].to_list()\n","res = []\n","for indx, tensor in enumerate(probs):\n","\n","    res.append(tensor[label_int[indx]])\n","submit['prob'] = res\n","del submit['probs'], submit['label_int']\n","tmp_submit = pd.DataFrame(submit.groupby(by=['oid', 'predict']).sum().reset_index())\n","\n","oid = tmp_submit['oid'].to_list()\n","predict = tmp_submit['predict'].to_list()\n","prob = tmp_submit['prob'].to_list()\n","\n","res = {}\n","for indx, id in enumerate(oid):\n","    if id not in res:\n","        res[id] = (predict[indx], prob[indx])\n","        \n","submit_data = {k:v[0] for k,v in res.items()}\n","oid = list(submit_data.keys())\n","predict = list(submit_data.values())\n","pd.DataFrame({'oid':oid, 'predict':predict}).to_csv('submission.csv', index=False,  encoding='utf-8-sig')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
